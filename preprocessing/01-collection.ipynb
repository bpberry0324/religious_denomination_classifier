{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cee95ab-4d65-491e-80ea-45bcd34e1ef7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initial Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a4333-403b-40de-9b08-db4faaad241a",
   "metadata": {},
   "source": [
    "Due to the time-intensive nature of collecting data in large swaths, posts from both subreddits in question were collected in two batches to account for occasional connection issues. Likewise, in an effort to maintain clean, readable Jupyter notebooks, this process was divided between this notebook and the next (`02_collection_continued.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af406f-06e4-4bf2-b34a-396d7796e0b7",
   "metadata": {},
   "source": [
    "Initial imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34c9992-11ef-4aa9-8088-18e1767f48b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56b179-5991-4a37-9116-418110896c41",
   "metadata": {},
   "source": [
    "Below, a standard function to pull subreddit data from PushShift. The function reads in a string (the name of the subreddit), constructs a longer URL string, and anchors the Unix timestamp in (what was at the time) a presrent value. Adding the `time.sleep` function to avoid any server dust-ups, it goes on to build a dataframe of 5000 rows, 100 rows at a time. A `print()` statement is added to provide a ticker and track the collection process. Finally, the information is written to a `.csv` file in the `datasets` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf5033b-f260-4e04-b65e-8fe685f5615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_scrape(subreddit):\n",
    "    s_type = 'submission'\n",
    "    unix_time_stamp = 1626825653\n",
    "    \n",
    "    url = f'https://api.pushshift.io/reddit/search/{s_type}/?subreddit={subreddit}&before={unix_time_stamp}&size=100'\n",
    "    \n",
    "    time.sleep(5)\n",
    "    res = requests.get(url)\n",
    "    post_list = res.json()['data']\n",
    "    full_df = pd.DataFrame(post_list)[['title', 'author', 'created_utc', 'selftext', 'subreddit' ]]\n",
    "    print(1)\n",
    "    \n",
    "    for n in range(1, 50):\n",
    "        uts = full_df['created_utc'].min()\n",
    "        url = f'https://api.pushshift.io/reddit/search/{s_type}/?subreddit={subreddit}&before={uts}&size=100'\n",
    "\n",
    "        time.sleep(5)\n",
    "        res = requests.get(url)\n",
    "\n",
    "        post_list = res.json()['data']\n",
    "        temp_df = pd.DataFrame(post_list)[['title', 'author', 'created_utc', 'selftext', 'subreddit' ]]\n",
    "\n",
    "        full_df = pd.concat([full_df, temp_df])\n",
    "        \n",
    "        print(n+1)\n",
    "        \n",
    "    full_df.to_csv('../datasets/' + subreddit + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755a36a-f3b0-49d3-8a47-b7e5c5f0dfd6",
   "metadata": {},
   "source": [
    "First, the Catholicism subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede27358-8fb8-4506-a258-86b9286da67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "reddit_scrape('Catholicism')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf392d6-f8aa-4f6d-8bfe-fe94c475bf60",
   "metadata": {},
   "source": [
    "Next, Orthodoxy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde9ddc1-6e43-49a1-9682-60283a91c08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "reddit_scrape('OrthodoxChristianity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458115d-7b7e-4a13-a53c-a2edc20a4aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
